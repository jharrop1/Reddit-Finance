{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dfcd38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.utils import resample\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.classify import ClassifierI\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "from statistics import mode\n",
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89186ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads the picled training data from the other module\n",
    "documents_f = open(\"pickled_outputs/documents.pickle\", \"rb\")\n",
    "documents = pickle.load(documents_f)\n",
    "documents_f.close()\n",
    "\n",
    "#Loads the features from the data\n",
    "vocab_features_f = open(\"pickled_outputs/vocab_features.pickle\", \"rb\")\n",
    "vocab_features = pickle.load(vocab_features_f)\n",
    "vocab_features_f.close()\n",
    "\n",
    "#Loads the fatureset\n",
    "featuresets_f = open(\"pickled_outputs/featuresets.pickle\", \"rb\")\n",
    "featuresets = pickle.load(featuresets_f)\n",
    "featuresets_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf88d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads the naieve bayes\n",
    "open_NB_file = open(\"pickled_outputs/naivebayes.pickle\", \"rb\")\n",
    "naive_bayes_classifier = pickle.load(open_NB_file)\n",
    "open_NB_file.close()\n",
    "\n",
    "#Loads the MNB\n",
    "open_MNB_file = open(\"pickled_outputs/MNB_classifier.pickle\", \"rb\")\n",
    "MNB_classifier = pickle.load(open_MNB_file)\n",
    "open_MNB_file.close()\n",
    "\n",
    "#Loads the BNB\n",
    "open_BNB_file = open(\"pickled_outputs/BNB_classifier.pickle\", \"rb\")\n",
    "BNB_classifier = pickle.load(open_BNB_file)\n",
    "open_BNB_file.close()\n",
    "\n",
    "#Loads the Logistic Regression\n",
    "open_LR_file = open(\"pickled_outputs/LogisticRegression_classifier.pickle\", \"rb\")\n",
    "LogisticRegression_classifier = pickle.load(open_LR_file)\n",
    "open_LR_file.close()\n",
    "\n",
    "#Loads the SGDC\n",
    "open_SGDC_file = open(\"pickled_outputs/SGDClassifier_classifier.pickle\", \"rb\")\n",
    "SGDClassifier_classifier = pickle.load(open_SGDC_file)\n",
    "open_SGDC_file.close()\n",
    "\n",
    "#Loads the SVC\n",
    "open_SVC_file = open(\"pickled_outputs/SVC_classifier.pickle\", \"rb\")\n",
    "SVC_classifier = pickle.load(open_SVC_file)\n",
    "open_SVC_file.close()\n",
    "\n",
    "\n",
    "#Loads the Linear SVC\n",
    "open_LSVC_file = open(\"pickled_outputs/LinearSVC_classifier.pickle\", \"rb\")\n",
    "LinearSVC_classifier = pickle.load(open_LSVC_file)\n",
    "open_LSVC_file.close()\n",
    "\n",
    "#NUSVC\n",
    "open_NUSVC_file = open(\"pickled_outputs/NuSVC_classifier.pickle\",\"rb\")\n",
    "NuSVC_classifier = pickle.load(open_NUSVC_file)\n",
    "open_NUSVC_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "326ad175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find feature function from the previous notebook\n",
    "def find_features(comment):\n",
    "    '''\n",
    "    Params:\n",
    "        document: our comment and sentiment\n",
    "    Return:\n",
    "        the features, a dictionary of words in the comment mapped to sentiment\n",
    "    '''\n",
    "    words = comment\n",
    "    features = {}\n",
    "\n",
    "    for w in vocab_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90375292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of featuresets:  3674\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of featuresets: \", len(featuresets))\n",
    "cutoff = round(len(featuresets) * 0.8)\n",
    "training_set = featuresets[:cutoff]\n",
    "testing_set = featuresets[cutoff+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05e8a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voting Class from previous notebook\n",
    "class VotingClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for classifier in self._classifiers:\n",
    "            vote = classifier.classify(features)\n",
    "            votes.append(vote)\n",
    "        return mode(votes)\n",
    "\n",
    "    def evaluate_confidence(self, features):\n",
    "        votes = []\n",
    "        for classifier in self._classifiers:\n",
    "            vote = classifier.classify(features)\n",
    "            votes.append(vote)\n",
    "            \n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        confidence = choice_votes / len(votes)\n",
    "        return confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6a774d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voting Classifier from previous notebook\n",
    "voting_classifier = VotingClassifier(naive_bayes_classifier, MNB_classifier, BNB_classifier, LogisticRegression_classifier, SGDClassifier_classifier, SVC_classifier, LinearSVC_classifier, NuSVC_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1786a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_sentiment(comment):\n",
    "    comment_features = find_features(comment)\n",
    "    return voting_classifier.classify(comment_features), voting_classifier.evaluate_confidence(comment_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ef87687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "define_sentiment(\"The market is great great today, I am super happy, I love money\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b798797c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "test = define_sentiment(\"I hate the down market its fucking bullshit, it is so negative I lost everything goodbye\")\n",
    "print(type(test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a0fc991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#Connect to a reddit account\n",
    "#Reddit account username: group_20_final_proj\n",
    "#Password: sharedaccount\n",
    "#Client ID: hMwEYlt_j8npjE5uqz1mcw\n",
    "#Seceret: mMt6cgv2tjF1VYZTT7c_BkmdvXOqVA\n",
    "\n",
    "#Connect to Reddit\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"hMwEYlt_j8npjE5uqz1mcw\",\n",
    "    client_secret=\"mMt6cgv2tjF1VYZTT7c_BkmdvXOqVA\",\n",
    "    user_agent=\"Group_20\",\n",
    "    username=\"group_20_final_proj\",\n",
    "    password=\"sharedaccount\",\n",
    ")\n",
    "print(reddit.read_only)\n",
    "# Output: False is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bec306b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wallstreetbets\n",
      "wallstreetbets\n"
     ]
    }
   ],
   "source": [
    "#Connect to a subreddit\n",
    "wallstreetbets = reddit.subreddit(\"wallstreetbets\")\n",
    "\n",
    "print(wallstreetbets.display_name)\n",
    "#Tests the connection\n",
    "print(wallstreetbets.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "331ccd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleans the file so it is empty\n",
    "wsb_output_text = open(\"wsb_output_text.txt\", \"w+\")\n",
    "wsb_output_text.close()\n",
    "wsb_output = open(\"wsb_output.txt\", \"w+\")\n",
    "wsb_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acd96587",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20808/1026353640.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mwsb_output_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"wsb_output_text.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#gets the sentiment value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0msentiment_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfidence_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefine_sentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#Writes the comment and sentiment to the output_text file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20808/2416109665.py\u001b[0m in \u001b[0;36mdefine_sentiment\u001b[1;34m(comment)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdefine_sentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mcomment_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mvoting_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomment_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoting_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_confidence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomment_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20808/3135227412.py\u001b[0m in \u001b[0;36mevaluate_confidence\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mvotes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_classifiers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mvote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mvotes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvote\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\classify\\api.py\u001b[0m in \u001b[0;36mclassify\u001b[1;34m(self, featureset)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \"\"\"\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moverridden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify_many\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify_many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\classify\\scikitlearn.py\u001b[0m in \u001b[0;36mclassify_many\u001b[1;34m(self, featuresets)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeaturesets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprob_classify_many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeaturesets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    622\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_sparse_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m  \u001b[1;31m# C is not useful here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m         return libsvm_sparse.libsvm_sparse_predict(\n\u001b[0m\u001b[0;32m    379\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_vectors_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Streaming the reddit api\n",
    "\n",
    "#subreddit.stream.comments(skip_existing=True) will start when the stream starts\n",
    "for comment in wallstreetbets.stream.comments():\n",
    "    #Opens the documents\n",
    "    wsb_output = open(\"wsb_output.txt\", \"a\")\n",
    "    wsb_output_text = open(\"wsb_output_text.txt\", \"a\", encoding=\"utf-8\")\n",
    "    #gets the sentiment value\n",
    "    sentiment_value, confidence_value = define_sentiment(comment.body)\n",
    "    \n",
    "    #Writes the comment and sentiment to the output_text file\n",
    "    wsb_output_text.write(comment.body + ' ' + ':' + ' ' + str(sentiment_value))\n",
    "    wsb_output_text.write('\\n')\n",
    "\n",
    "    #Writes the sentiment to the output file\n",
    "    wsb_output.write(str(sentiment_value))\n",
    "    wsb_output.write('\\n')\n",
    "    wsb_output.close\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1938cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
